# TIA: Tocantins Intelig√™ncia Artificial üöÄ

A **TIA (Tocantins Intelig√™ncia Artificial)** √© uma infraestrutura multi-agente robusta, projetada para servir como o ponto central de intera√ß√£o entre o cidad√£o e o Governo do Estado do Tocantins. Diferente de chatbots convencionais, a TIA utiliza uma arquitetura de orquestra√ß√£o din√¢mica que permite a expans√£o modular de compet√™ncias atrav√©s de agentes especialistas independentes.

---

## ÔøΩÔ∏è Arquitetura e Tecnologias

O sistema √© dividido em tr√™s camadas principais, garantindo escalabilidade, fidelidade de dados e flexibilidade de modelos.

### 1. Frontend: Experi√™ncia do Usu√°rio (UX)
Constru√≠do com tecnologias modernas para oferecer uma interface de alta performance e responsividade:
- **React 18 & TypeScript**: Desenvolvimento baseado em componentes com tipagem estrita, garantindo manutenibilidade.
- **Vite & Rolldown**: Pipeline de build ultra-r√°pido.
- **Design System Customizado**:
  - **Tailwind CSS**: Estiliza√ß√£o utilit√°ria para design consistente.
  - **Radix UI**: Primitivas de UI acess√≠veis para modais, abas e componentes complexos.
  - **Lucide React**: Iconografia sem√¢ntica.
- **Rich Feedback**: Sistema de mensagens de carregamento din√¢micas que notificam o usu√°rio sobre a etapa atual do processamento da IA (ex: consulta ao RAG, valida√ß√£o de fontes).

### 2. Backend: Orquestra√ß√£o e L√≥gica de Neg√≥cio
O motor do sistema, respons√°vel por gerenciar a comunica√ß√£o entre usu√°rios, agentes e modelos:
- **Python (Flask)**: Servidor ass√≠ncrono que utiliza `asyncio` para lidar com m√∫ltiplas requisi√ß√µes simult√¢neas de streaming de IA.
- **Google ADK (Agent Development Kit)**: Framework central que define a l√≥gica de "Runners" e "Sessions". Ele permite que cada conversa mantenha seu hist√≥rico e contexto isoladamente.
- **Service Layer**:
  - **Scraping Engine**: Baseada em Scrapy, permite alimentar a base de conhecimento com dados frescos dos portais oficiais.
  - **Session Management**: Controle de sess√µes em mem√≥ria para respostas r√°pidas.

### 3. Camada de Intelig√™ncia (LLM Engine)
A TIA √© agn√≥stica a modelos, permitindo o uso de diversas LLMs de forma simult√¢nea ou alternada:

#### **Modelos em Nuvem (Cloud)**
- **Google Gemini (2.0/2.5 Flash & Pro)**: Integra√ß√£o nativa via Google GenAI SDK. Utilizado como modelo principal para orquestra√ß√£o devido √† alta janela de contexto e capacidades de RAG (File Search).
- **DeepSeek V3**: Integrado via **LiteLLM**, oferecendo uma alternativa de alto racioc√≠nio para quest√µes complexas de legisla√ß√£o e tributa√ß√£o.

#### **Modelos Locais (Localhost / Docker)**
O sistema possui suporte nativo para infer√™ncia local, garantindo soberania de dados e redu√ß√£o de custos:
- **Gemma Local**: Implementado para rodar em containers Docker ou via **Ollama** (endpoint `http://localhost:12434`).
- **DeepSeek Local**: Suporte para modelos rodando localmente (ex: DeepSeek-V3-base) via integra√ß√£o LiteLLM Local.
- **Hot-Swapping**: O backend permite trocar o modelo ativo em tempo real atrav√©s da API `/api/models`, sem necessidade de reiniciar os servi√ßos.

---

## ÔøΩ O Cora√ß√£o do Sistema: Multi-Agent RAG

A TIA n√£o responde apenas com base em sua mem√≥ria de treinamento. Ela utiliza um fluxo de **RAG (Retrieval-Augmented Generation)** rigoroso:

1. **Triagem (Orquestrador)**: A TIA analisa a d√∫vida e identifica se deve respond√™-la ou invocar um dos **57 Agentes Especialistas** (ex: Detran, SEFAZ, Sa√∫de).
2. **Busca Sem√¢ntica (File Search)**: O agente relevante acessa uma "Knowledge Store" (Base de Conhecimento) espec√≠fica, contendo PDFs, Leis e Manuais formatados em Markdown.
3. **Restri√ß√£o de Fontes**: O sistema √© instru√≠do a ignorar fontes de terceiros (blogs ou not√≠cias) e focar apenas em dom√≠nios `*.to.gov.br` e `*.al.to.leg.br`.
4. **Padroniza√ß√£o de Links**: Uma camada de p√≥s-processamento converte automaticamente links obsoletos encontrados na base antiga para os novos links do Portal Unificado (ex: `sefaz.to.gov.br` ‚Üí `to.gov.br/sefaz`).

---

## ÔøΩÔ∏è Guia de Implementa√ß√£o T√©cnica

### Requisitos de Ambiente
- **Node.js 20+** e **Python 3.11+**
- **Docker** (Opcional, necess√°rio para modelos locais)

### Fluxo de Inicializa√ß√£o
1. **Configura√ß√£o de Agentes**: O script `atualizar_agentes.py` l√™ o `MAPEAMENTO_COMPETENCIAS.py` e gera os arquivos JSON individuais para cada secretaria, injetando as regras globais de tom de voz e cita√ß√£o.
2. **Setup do RAG**: Documentos MD s√£o processados e enviados para as Stores via API, ficando dispon√≠veis para o `File Search` do Gemini.
3. **Infer√™ncia**: O `app.py` recebe a mensagem via `/api/chat`, instancia o `InMemoryRunner` com o agente adequado e gerencia o streaming de eventos at√© a resposta final.

---

## ÔøΩÔ∏è Seguran√ßa e Privacidade
- **Isolamento de Sess√£o**: Cada usu√°rio possui um UUID de sess√£o √∫nico, impedindo vazamento de contexto entre conversas.
- **Filtragem de Alucina√ß√£o**: Instru√ß√µes r√≠gidas de sistema pro√≠bem a cria√ß√£o de links que n√£o existam na base oficial, mitigando um dos problemas mais comuns em LLMs.

---

**TIA - Intelig√™ncia a servi√ßo do cidad√£o do Tocantins.**
